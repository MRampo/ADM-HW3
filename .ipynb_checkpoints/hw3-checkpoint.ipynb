{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\auror\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from tqdm import tqdm \n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "from nltk.stem import *\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import tokenize\n",
    "import datatable as dt \n",
    "import csv\n",
    "\n",
    "\n",
    "#To read and store dictionary\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#EDA\n",
    "#do Lemmatization in the Data Cleaning \n",
    "#Create all the missing tsv\n",
    "#Clean and comment the code\n",
    "#CHECK EFFICIENCY 1.2 and 1.3\n",
    "#Parse list before saving into"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data collection\n",
    "## 1.1. Get the list of places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_link = []\n",
    "s = requests.Session()\n",
    "for n in tqdm(range(1,401)):\n",
    "    url = f'https://www.atlasobscura.com/places?page={n}&sort=likes_count'\n",
    "    result = s.get(url)\n",
    "    soup = bs(result.text)\n",
    "    puf = soup.find_all(\"a\", {'class': 'content-card content-card-place'})\n",
    "    for x in puf:\n",
    "        total_link.append(x['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('total_link.txt',\"r\")\n",
    "total_link = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Crawl places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadPage(start,end, array):\n",
    "    count_link = ((start-1)*18)+1\n",
    "    count_page = start\n",
    "    \n",
    "    parent_dir = f'./all_Pages'\n",
    "    s = requests.Session()\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    for x in tqdm(range(start, end)):\n",
    "        if count_link%10 == 0:\n",
    "            s = requests.Session()\n",
    "        if count_link%18 == 1:\n",
    "            path = os.path.join(parent_dir, f\"folder_{count_page}\")\n",
    "            os.mkdir(path)\n",
    "        for y in range(18):\n",
    "            url = f'https://www.atlasobscura.com{array[count_link-1]}'\n",
    "            name_file = f'location_{count_link}'\n",
    "            name_folder = f'folder_{count_page}'\n",
    "            with open(f'./all_Pages/{name_folder}/{name_file}.html', 'w', encoding='utf8') as fp:\n",
    "                req = s.get(url, headers = header)\n",
    "                fp.write(req.text)\n",
    "                if req.status_code != 200:\n",
    "                     time.sleep(120)\n",
    "                     req = s.get(url, headers = header)\n",
    "                fp.write(s.get(url).text)\n",
    "            if count_link%18 == 0:\n",
    "                count_page += 1\n",
    "            count_link += 1\n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_TSV():\n",
    "    os.mkdir(\"TSV Files\")\n",
    "    for x in os.listdir(\"all_Pages\"):\n",
    "        for y in os.listdir(f'all_Pages/{x}'):\n",
    "            with open(f'./all_Pages/{x}/{y}', encoding='utf8') as f:\n",
    "                p = f.read()\n",
    "                soup =  bs(p)\n",
    "                pageAttribute = []\n",
    "                placeName = findPlaceName(soup)\n",
    "                placeTags = findPlaceTags(soup)\n",
    "                numPeopleVisited = findNumPeopleVisited(soup)\n",
    "                numPeopleWant = findNumPeopleWant(soup)\n",
    "                placeDesc = findDescription(soup)\n",
    "                placeShortDesc = findShortDescription(soup)\n",
    "                placeNearby = findNearbyPlaces(soup)\n",
    "                placeAddress = findAddress(soup)\n",
    "                placeAlt, placeLong = findCordinates(soup)\n",
    "                placeEditors = findPostEditors(soup)\n",
    "                placePubDate = findPublishingDate(soup)\n",
    "                placeRelatedList = findPlaceNear(soup)\n",
    "                placeRelatedPlaces = findRelatedPlaces(soup)\n",
    "                placeURL = findPageURL(soup)\n",
    "                with open(f'./TSV Files/{y[:-5]}.tvs', 'wt', encoding='utf8') as fp:\n",
    "                    csv.writer(fp, delimiter='\\t').writerow([placeName, placeTags, numPeopleVisited, numPeopleWant, placeDesc, placeShortDesc, placeNearby, placeAddress, placeAlt, placeLong, placeEditors, placePubDate, placeRelatedList, placeRelatedPlaces, placeURL])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_TSV():\n",
    "    os.mkdir(\"TSV Files\")\n",
    "    a = 0\n",
    "    for path in tqdm(glob.glob(r\"all_Pages/*/*\")):\n",
    "        with open(path, encoding='utf8') as f:\n",
    "                    a += 1\n",
    "                    p = f.read()\n",
    "                    soup =  bs(p)\n",
    "                    pageAttribute = []\n",
    "                    placeName = findPlaceName(soup)\n",
    "                    placeTags = findPlaceTags(soup)\n",
    "                    placeTags = \",\".join(placeTags)\n",
    "                    numPeopleVisited = findNumPeopleVisited(soup)\n",
    "                    numPeopleWant = findNumPeopleWant(soup)\n",
    "                    placeDesc = findDescription(soup)\n",
    "                    placeDesc = \" \".join(placeDesc)\n",
    "                    placeShortDesc = findShortDescription(soup)\n",
    "                    placeNearby = findNearbyPlaces(soup)\n",
    "                    placeNearby = \",\".join(placeNearby)\n",
    "                    placeAddress = findAddress(soup)\n",
    "                    placeAlt, placeLong = findCordinates(soup)\n",
    "                    placeEditors = findPostEditors(soup)\n",
    "                    placeEditors = \",\".join(placeEditors)\n",
    "                    placePubDate = findPublishingDate(soup)\n",
    "                    placeRelatedList = findPlaceNear(soup)\n",
    "                    placeRelatedList = \",\".join(placeRelatedList)\n",
    "                    placeRelatedPlaces = findRelatedPlaces(soup)\n",
    "                    placeRelatedPlaces = \",\".join(placeRelatedPlaces)\n",
    "                    placeURL = findPageURL(soup)\n",
    "                    with open(f'./TSV Files/{a}.tvs', 'wt', encoding='utf8') as fp:\n",
    "                        csv.writer(fp, delimiter='\\t').writerow([placeName, placeTags, numPeopleVisited, numPeopleWant, placeDesc, placeShortDesc, placeNearby, placeAddress, placeAlt, placeLong, placeEditors, placePubDate, placeRelatedList, placeRelatedPlaces, placeURL])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_TSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPlaceName(soup):\n",
    "    placeName = soup.find(\"h1\", {\"class\": \"DDPage__header-title\"})\n",
    "    if placeName != None:\n",
    "        placeName = placeName.text\n",
    "    #placeName = re.sub('[A-Za-z0-9_.,! \"]*' ,'',placeName)\n",
    "    return placeName\n",
    "\n",
    "def findPlaceTags(soup):\n",
    "    tags = []\n",
    "    placeTags = soup.find_all(\"a\", {\"class\": \"itemTags__link js-item-tags-link\"})\n",
    "    for tag in placeTags:\n",
    "        t = tag.text.replace(\"\\n\", \"\")\n",
    "        #t = re.sub('[A-Za-z0-9 _.,!\"]*','',t)\n",
    "        tags.append(t)\n",
    "    return tags\n",
    "\n",
    "def findNumPeopleVisited(soup):\n",
    "    peopleVisited = soup.find_all(\"div\", {\"class\": \"title-md item-action-count\"})\n",
    "    if len(peopleVisited) > 0:\n",
    "        peopleVisited = int(peopleVisited[0].text)\n",
    "    return peopleVisited\n",
    "\n",
    "def findNumPeopleWant(soup):\n",
    "    peopleVisited = soup.find_all(\"div\", {\"class\": \"title-md item-action-count\"})\n",
    "    if len(peopleVisited) > 0:\n",
    "        peopleVisited = int(peopleVisited[1].text)\n",
    "    return peopleVisited\n",
    "\n",
    "def findDescription(soup):\n",
    "    all_description = []\n",
    "    descriptions = soup.find_all(\"div\", {\"class\": \"DDP__body-copy\"})\n",
    "    for description in descriptions:\n",
    "        d = description.text.replace(\"\\n\",\"\")\n",
    "        all_description.append(d)\n",
    "    return all_description\n",
    "\n",
    "def findShortDescription(soup):\n",
    "    shortDescription = soup.find(\"h3\", {\"class\": \"DDPage__header-dek\"})\n",
    "    if shortDescription != None:\n",
    "        shortDescription = shortDescription.text.replace(\"\\n\", \"\")\n",
    "    return shortDescription\n",
    "\n",
    "def findNearbyPlaces(soup):\n",
    "    nearPlaces = []\n",
    "    nearbyPlaces = soup.find_all(\"div\", {\"class\": \"DDPageSiderailRecirc__item-title\"})\n",
    "    if nearbyPlaces != None:\n",
    "        for place in nearbyPlaces:\n",
    "            p = place.text.replace(\"\\n\",\"\")\n",
    "            nearPlaces.append(p)\n",
    "        #Convert the list to set, and then back again to list to remove repetition\n",
    "    return set(nearPlaces)\n",
    "\n",
    "def findAddress(soup):\n",
    "    strings = []\n",
    "    adress_strings = soup.find(\"address\", {\"class\": \"DDPageSiderail__address\"})\n",
    "    if adress_strings != None:\n",
    "        adress_strings = adress_strings.find(\"div\")\n",
    "        for info in adress_strings:\n",
    "            s = info.text.replace(\"\\n\", \"\")\n",
    "            if s != \"\":\n",
    "                strings.append(s)\n",
    "        if len(strings) > 3:\n",
    "            return \" \".join(strings[:3])\n",
    "    else:\n",
    "        return \" \"\n",
    "\n",
    "def findCordinates(soup):\n",
    "\n",
    "    cordinates = soup.find(\"div\", {\"class\":\"DDPageSiderail__coordinates js-copy-coordinates\"})\n",
    "    if cordinates != None:\n",
    "        return cordinates.text.replace(\"\\n\", \"\").replace(\" \",\"\").split(\",\")\n",
    "    return \" \", \" \"\n",
    "\n",
    "def findPostEditors(soup):\n",
    "    all_editors =[]\n",
    "    editors = soup.find_all(\"a\", {\"class\":\"DDPContributorsList__contributor\"})         \n",
    "    for person in editors:\n",
    "        s = person.text.replace(\"\\n\", \"\")\n",
    "        all_editors.append(s)\n",
    "    return all_editors\n",
    "\n",
    "def findPublishingDate(soup):\n",
    "    #Pick the right info\n",
    "    dateString = soup.find(\"div\", {\"class\":\"DDPContributor__name\"}) \n",
    "    #Let's clean the string\n",
    "    if dateString != None:\n",
    "        s = dateString.text.replace(\"\\n\", \"\")\n",
    "        #Let's modify it for the right format of datetime\n",
    "        split = s.split()\n",
    "        #Let's convert the string Month into the corrispondent number by using \"strptime()\" \n",
    "        split[0] = str(datetime.datetime.strptime(split[0], '%B').month)\n",
    "        #My format\n",
    "        format = \"%m %d, %Y\"\n",
    "        #Convert from String to datetime\n",
    "        date = datetime.datetime.strptime(\" \".join(split), format)\n",
    "        return date\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def findPlaceNear(soup):\n",
    "    lists =[]\n",
    "    relatedLists = soup.find(\"div\", {\"data-gtm-template\":\"DDP Footer Recirc Nearby\"})\n",
    "    if relatedLists != None:\n",
    "        relatedLists = relatedLists.find_all(\"h3\", {\"class\":\"Card__heading --content-card-v2-title js-title-content\"})\n",
    "        for list in relatedLists:\n",
    "            s = list.text.replace(\"\\n\", \"\")\n",
    "            #s = re.sub('[A-Za-z0-9 _.,!\"]*','',s)\n",
    "            lists.append(s)\n",
    "    return lists\n",
    "\n",
    "def findRelatedPlaces(soup):\n",
    "    lists =[]\n",
    "    relatedLists = soup.find(\"div\", {\"data-gtm-template\":\"DDP Footer Recirc Related\"})\n",
    "    if relatedLists != None:\n",
    "        relatedLists = relatedLists.find_all(\"h3\", {\"class\":\"Card__heading --content-card-v2-title js-title-content\"})\n",
    "        for list in relatedLists:\n",
    "            s = list.text.replace(\"\\n\", \"\")\n",
    "            #s = re.sub('[A-Za-z0-9 _.,!\"]*','',s)\n",
    "            lists.append(s)\n",
    "    return lists\n",
    "\n",
    "def findPageURL(soup):\n",
    "    numVisitedPeople = soup.find(\"link\", {\"rel\":\"canonical\"})\n",
    "    return numVisitedPeople['href']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the tsv file into one pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to save all the .tsv file as one joined .csv where every file rappresents one row of the .csv file, so that we can work and access the data without having to read 7200 tsv file each time. The data are stored in the \"tsv_dataframe\"\n",
    "\n",
    "This mean that the function load_tsv() has only been executed once. The other iteration we just read the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_tsv():\n",
    "    tsv = []\n",
    "    dtypes = {}\n",
    "    for x in tqdm(os.listdir(\"TSV Files\")):\n",
    "        df = pd.read_csv(f'TSV Files/{x}',\n",
    "            sep=\"\\t\",\n",
    "            header=None,\n",
    "            names=[\"placeName\", \"placeTags\", \"numPeopleVisited\", \"numPeopleWant\", \"placeDesc\", \"placeShortDesc\", \"placeNearby\",\"placeAdress\", \"placeAlt\", \"placeLong\", \"placeEditors\",\"placePubDate\", \"placeRelatedList\", \"placeRelatedPlace\", \"placeURL\"])\n",
    "        tsv.append(df)\n",
    "\n",
    "    return pd.concat(tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_tsv()\n",
    "data = pd.read_csv(\"tsv_dataframe.csv\",index_col=0)\n",
    "\n",
    "#Reset Index\n",
    "data.reset_index(inplace = True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('numPeopleWant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "- remove punctuation \n",
    "- remove stopwords \n",
    "- stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_punctuations(string):\n",
    "    # first we remove the punctuations\n",
    "    # in order to do it we need to tekenize the string with the function tokenize and then applying the function RegexpTokenizer\n",
    "    return RegexpTokenizer(r'\\w+').tokenize(string)\n",
    "\n",
    "\n",
    "def stemming(string):\n",
    "    # now we move forward with the stemming\n",
    "    porter = PorterStemmer()\n",
    "    string_stem=[porter.stem(word) for word in string]\n",
    "    # we can now return the cleaned string \n",
    "    return string_stem\n",
    "\n",
    "def remove_stopwords(string):\n",
    "    # after this we can now remove all the stopwords in each word in string_t\n",
    "    return  [word for word in string if not word.lower() in set(stopwords.words(\"english\"))]\n",
    "    # now we move forward with the stemming\n",
    "\n",
    "def cleaning(string):\n",
    "    #I apply all the function for cleaning the string\n",
    "    string = string.lower()\n",
    "    string = remove_punctuations(string)\n",
    "    string = remove_stopwords(string)\n",
    "    string = stemming(string)\n",
    "\n",
    "    #return a list containing all the words of the original string after the cleaning\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first dictionary where every key is a word and it's value is the corrispondant number to that word\n",
    "\n",
    "def createFirstDic(data):\n",
    "    dic = {}\n",
    "    value = 1\n",
    "    for description in tqdm(data[\"placeDesc\"]):\n",
    "        #Cleaning the data\n",
    "        description = cleaning(description)\n",
    "        for word in description:\n",
    "            if word in dic.keys():\n",
    "                continue\n",
    "            else:\n",
    "                dic[word] = value\n",
    "                value += 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7200/7200 [09:32<00:00, 12.58it/s]\n"
     ]
    }
   ],
   "source": [
    "dic1 = createFirstDic(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dic1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 Creating your index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSecondDic(data, dic1):\n",
    "    dic2 = {}\n",
    "    a = 0\n",
    "    for description in data[\"placeDesc\"]:\n",
    "        #Cleaning the data\n",
    "        description= cleaning(description)\n",
    "        for word in description:\n",
    "            if dic1[word] in dic2.keys():\n",
    "                dic2[dic1[word]].add(data.placeName[a])\n",
    "            else:\n",
    "                dic2[dic1[word]] = set([data.placeName[a]])\n",
    "        a += 1\n",
    "    return dic2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2 = createSecondDic(data,dic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dic(dic, name):\n",
    "    with open(f'{name}.pkl', 'wb') as f:\n",
    "        pickle.dump(dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dic(name):\n",
    "    with open(f'{name}.pkl', 'rb') as f:\n",
    "        loaded_dict = pickle.load(f)\n",
    "        return loaded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic1 = read_dic(\"dic1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(list):\n",
    "    s = dic2[dic1[list[0]]]\n",
    "    for x in range(1, len(list)):\n",
    "        s.intersection(dic2[dic1[list[x]]])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = query([\"class\", \"including\"])\n",
    "\n",
    "res_query = data[data['placeName'].isin(list(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_query.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(txt):\n",
    "    return [word for word in txt.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['list_words'] = data.placeDesc.apply(lambda row: stem_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "x =vectorizer.fit_transform(data.placeDesc).todense()\n",
    "df = pd.DataFrame(x, columns = \n",
    "vectorizer.get_feature_names())\n",
    "df\n",
    "#vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInvertedIndex(data, dic1):\n",
    "    dic2 = {}\n",
    "    a = 0\n",
    "    for description in data[\"placeDesc\"]:\n",
    "        description = description.replace('\\'',\"\")\n",
    "        description = description.replace('[',\"\")\n",
    "        description = description.replace(']',\"\")\n",
    "        description = description.lower()\n",
    "        for word in description.split():\n",
    "            if dic1[word] in dic2.keys():\n",
    "                dic2[dic1[word]].add(data.placeName[a])\n",
    "            else:\n",
    "                b = []\n",
    "                dic2[dic1[word]] = set([data.placeName[a]])\n",
    "            # print(dic2)\n",
    "        a += 1\n",
    "    return dic2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a new score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert the words that you want to be found in the description's places: american museum\n"
     ]
    }
   ],
   "source": [
    "query_user = list(input(\"Insert the words that you want to be found in the description's places: \").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placeName</th>\n",
       "      <th>placeTags</th>\n",
       "      <th>numPeopleVisited</th>\n",
       "      <th>numPeopleWant</th>\n",
       "      <th>placeDesc</th>\n",
       "      <th>placeShortDesc</th>\n",
       "      <th>placeNearby</th>\n",
       "      <th>placeAdress</th>\n",
       "      <th>placeAlt</th>\n",
       "      <th>placeLong</th>\n",
       "      <th>placeEditors</th>\n",
       "      <th>placePubDate</th>\n",
       "      <th>placeRelatedList</th>\n",
       "      <th>placeRelatedPlace</th>\n",
       "      <th>placeURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amityville Horror House</td>\n",
       "      <td>hoaxes and pseudoscience,haunted,film location...</td>\n",
       "      <td>367</td>\n",
       "      <td>831</td>\n",
       "      <td>On a cold November night in 1974, Amityville, ...</td>\n",
       "      <td>The site of a tragic massacre that spawned a m...</td>\n",
       "      <td>The Long Island Puppet Theater,Pilgrim Psychia...</td>\n",
       "      <td>112 Ocean Avenue Amityville, New York, 11701 U...</td>\n",
       "      <td>40.6665</td>\n",
       "      <td>-73.4143</td>\n",
       "      <td>EricGrundhauser,MandrewPatinkin,lendog666,Mart...</td>\n",
       "      <td>2013-10-17 00:00:00</td>\n",
       "      <td>The Long Island Puppet Theater,Fire Island Lig...</td>\n",
       "      <td>Conanicut Island Lighthouse,Lovell Health Hous...</td>\n",
       "      <td>https://www.atlasobscura.com/places/amityville...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>American Prohibition Museum</td>\n",
       "      <td>speakeasies,prohibition,law,food museums,alcoh...</td>\n",
       "      <td>368</td>\n",
       "      <td>832</td>\n",
       "      <td>When the 18th Amendment to the U.S. Constituti...</td>\n",
       "      <td>Performers, intricate sets, and a real speakea...</td>\n",
       "      <td>The Paris Market,Riverside Plant Hotel,The Mar...</td>\n",
       "      <td>209 W. St. Julian Street Savannah, Georgia Uni...</td>\n",
       "      <td>32.0806</td>\n",
       "      <td>-81.0946</td>\n",
       "      <td>Edward Denny,Collector of Experiences,theparan...</td>\n",
       "      <td>2018-11-26 00:00:00</td>\n",
       "      <td>The Paris Market,Riverside Plant Hotel,The Mar...</td>\n",
       "      <td>Booze History Museum,Linos tou Charilaou (Omod...</td>\n",
       "      <td>https://www.atlasobscura.com/places/american-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wild Blueberry Land</td>\n",
       "      <td>blueberries,maine,miniature golf,theme parks,f...</td>\n",
       "      <td>225</td>\n",
       "      <td>1027</td>\n",
       "      <td>There is no shortage of bizarre American highw...</td>\n",
       "      <td>This colorful theme park dedicated the officia...</td>\n",
       "      <td>Maine Central Model Railroad,Maine Coast Sardi...</td>\n",
       "      <td>1067 US HWY 1 Columbia Falls, Maine United States</td>\n",
       "      <td>44.6487</td>\n",
       "      <td>-67.7069</td>\n",
       "      <td>Lauren J Young,basimonica11,hana</td>\n",
       "      <td>2016-08-16 00:00:00</td>\n",
       "      <td>Maine Central Model Railroad,Nellie Chapin Day...</td>\n",
       "      <td>Sadpol Strawberry,Monticello's Vegetable Garde...</td>\n",
       "      <td>https://www.atlasobscura.com/places/wild-blueb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>The Avrocar</td>\n",
       "      <td>retro-tech,inventions</td>\n",
       "      <td>387</td>\n",
       "      <td>830</td>\n",
       "      <td>The year was 1952 and the Cold War was in full...</td>\n",
       "      <td>A real flying saucer, contracted by the U.S. A...</td>\n",
       "      <td>National Museum of the U.S. Air Force,SAM 2600...</td>\n",
       "      <td>1100 Spaatz Street Wright-Patterson AFB Dayton...</td>\n",
       "      <td>39.7822</td>\n",
       "      <td>-84.1077</td>\n",
       "      <td>canuck,Kiri the Unicorn,shaunk82,Ahuntley,mord...</td>\n",
       "      <td>2010-07-01 00:00:00</td>\n",
       "      <td>SAM 26000,National Museum of the U.S. Air Forc...</td>\n",
       "      <td>Le Téléscaphe,Edison's Last Breath,Swing at th...</td>\n",
       "      <td>https://www.atlasobscura.com/places/avrocar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Laurel Dinosaur Park</td>\n",
       "      <td>dinosaur parks,bones,dinosaurs,fossils,parks,a...</td>\n",
       "      <td>126</td>\n",
       "      <td>825</td>\n",
       "      <td>During the 18th and 19th centuries, clay forma...</td>\n",
       "      <td>This dig site outside D.C. is known for its ex...</td>\n",
       "      <td>Smokey Bear Archive,On the Brink,Pinball Parlo...</td>\n",
       "      <td>13100 Mid Atlantic Blvd Laurel, Maryland Unite...</td>\n",
       "      <td>39.0708</td>\n",
       "      <td>-76.8686</td>\n",
       "      <td>WhiskeyBristles,annakovach,ickaimp,kristingail</td>\n",
       "      <td>2017-06-05 00:00:00</td>\n",
       "      <td>Smokey Bear Archive,Pinball Parlor at MOM's Or...</td>\n",
       "      <td>Capitalsaurus Court,Enciso Ichnites,Castilla-L...</td>\n",
       "      <td>https://www.atlasobscura.com/places/laurel-din...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Mars Bluff Crater</td>\n",
       "      <td>atom bombs,nuclear,disaster areas,disasters,in...</td>\n",
       "      <td>157</td>\n",
       "      <td>823</td>\n",
       "      <td>It is not often spoken about, but it’s an unse...</td>\n",
       "      <td>\"Not too many people can say they've had a nuc...</td>\n",
       "      <td>The Last Yogi Bear Honey Fried Chicken Restaur...</td>\n",
       "      <td>Crater Rd. Mars Bluff Florence, South Carolina...</td>\n",
       "      <td>34.2011</td>\n",
       "      <td>-79.6564</td>\n",
       "      <td>rachel777,treytatum,Rachel,Martin,Mark Casey,z...</td>\n",
       "      <td>2013-03-19 00:00:00</td>\n",
       "      <td>Blenheim Mineral Springs,Woods Bay State Park,...</td>\n",
       "      <td>Hiroshima's Hypocenter,Lucky Dragon and Atomic...</td>\n",
       "      <td>https://www.atlasobscura.com/places/mars-bluff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Boothill Graveyard</td>\n",
       "      <td>wild west,relics and reliquaries,memento mori,...</td>\n",
       "      <td>1184</td>\n",
       "      <td>823</td>\n",
       "      <td>In these modern times, death is portrayed as u...</td>\n",
       "      <td>A wild west cemetery in Tombstone, Arizona, pr...</td>\n",
       "      <td>Jewish Pioneers Memorial,Rose Tree Museum,St. ...</td>\n",
       "      <td>Boothill Graveyard 408 Arizona Hwy 80 Tombston...</td>\n",
       "      <td>31.7199</td>\n",
       "      <td>-110.0702</td>\n",
       "      <td>Mark Casey,mordred350,CorpseLady84,Rachel,dlc3...</td>\n",
       "      <td>2012-04-03 00:00:00</td>\n",
       "      <td>Jewish Pioneers Memorial,St. Paul’s Episcopal ...</td>\n",
       "      <td>Boot Hill Cemetery,Grave of W. B. Yeats,John W...</td>\n",
       "      <td>https://www.atlasobscura.com/places/boothill-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Lion of Lucerne</td>\n",
       "      <td>literature,military history,monuments,sculptur...</td>\n",
       "      <td>896</td>\n",
       "      <td>823</td>\n",
       "      <td>Created to remember the hundreds of Swiss Guar...</td>\n",
       "      <td>This memorial commemorating fallen Swiss Guard...</td>\n",
       "      <td>Barabas Hotel Luzern,Dance of Death Bridge,Ham...</td>\n",
       "      <td>Denkmalstrasse 4 Lucerne, 6006 Switzerland</td>\n",
       "      <td>47.0585</td>\n",
       "      <td>8.3109</td>\n",
       "      <td>ectoman3,Annetta Black,mikeslolady1,gzhtub,Mar...</td>\n",
       "      <td>2013-12-05 00:00:00</td>\n",
       "      <td>Barabas Hotel Luzern,Dance of Death Bridge,Ham...</td>\n",
       "      <td>Wellington Monument ,Napoleon's Angels,The Win...</td>\n",
       "      <td>https://www.atlasobscura.com/places/lion-of-lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Thain Family Forest</td>\n",
       "      <td>botanical gardens,flora,cities,forests,trees,e...</td>\n",
       "      <td>173</td>\n",
       "      <td>820</td>\n",
       "      <td>This small forest in the Bronx could be the mo...</td>\n",
       "      <td>This plot of old-growth forest is the largest ...</td>\n",
       "      <td>Fordham Cemetery,Bronx Zoo 'Fountain of Youth'...</td>\n",
       "      <td>2900 Southern Blvd Bronx, New York United States</td>\n",
       "      <td>40.8644</td>\n",
       "      <td>-73.8757</td>\n",
       "      <td>Luke J Spencer,vbl,Anna Minster,imrantabish16</td>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>Holiday Train Show at New York Botanical Garde...</td>\n",
       "      <td>Fragas do Eume,Trollskogen (The Troll Forest),...</td>\n",
       "      <td>https://www.atlasobscura.com/places/thain-fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Maxwell Blade’s Odditorium and Curiosities Museum</td>\n",
       "      <td>magic,taxidermy,museums and collections</td>\n",
       "      <td>130</td>\n",
       "      <td>821</td>\n",
       "      <td>This “Odditorium” features a collection of ove...</td>\n",
       "      <td>An ever-growing collection of rare and strange...</td>\n",
       "      <td>Josephine Tussaud Wax Museum ,The Arlington Ho...</td>\n",
       "      <td>817 Central Ave Hot Springs, Arkansas, 71901 U...</td>\n",
       "      <td>34.5087</td>\n",
       "      <td>-93.0539</td>\n",
       "      <td>seh256,Erik,notoriousFIG,Collector of Experien...</td>\n",
       "      <td>2016-07-13 00:00:00</td>\n",
       "      <td>Josephine Tussaud Wax Museum ,The Arlington Ho...</td>\n",
       "      <td>The Insect Asylum ,Hand of Man Museum,Dreamfac...</td>\n",
       "      <td>https://www.atlasobscura.com/places/maxwell-bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            placeName  \\\n",
       "3                             Amityville Horror House   \n",
       "6                         American Prohibition Museum   \n",
       "13                                Wild Blueberry Land   \n",
       "39                                       The Avrocar    \n",
       "59                               Laurel Dinosaur Park   \n",
       "77                                  Mars Bluff Crater   \n",
       "78                                 Boothill Graveyard   \n",
       "88                                    Lion of Lucerne   \n",
       "91                                Thain Family Forest   \n",
       "92  Maxwell Blade’s Odditorium and Curiosities Museum   \n",
       "\n",
       "                                            placeTags  numPeopleVisited  \\\n",
       "3   hoaxes and pseudoscience,haunted,film location...               367   \n",
       "6   speakeasies,prohibition,law,food museums,alcoh...               368   \n",
       "13  blueberries,maine,miniature golf,theme parks,f...               225   \n",
       "39                              retro-tech,inventions               387   \n",
       "59  dinosaur parks,bones,dinosaurs,fossils,parks,a...               126   \n",
       "77  atom bombs,nuclear,disaster areas,disasters,in...               157   \n",
       "78  wild west,relics and reliquaries,memento mori,...              1184   \n",
       "88  literature,military history,monuments,sculptur...               896   \n",
       "91  botanical gardens,flora,cities,forests,trees,e...               173   \n",
       "92            magic,taxidermy,museums and collections               130   \n",
       "\n",
       "    numPeopleWant                                          placeDesc  \\\n",
       "3             831  On a cold November night in 1974, Amityville, ...   \n",
       "6             832  When the 18th Amendment to the U.S. Constituti...   \n",
       "13           1027  There is no shortage of bizarre American highw...   \n",
       "39            830  The year was 1952 and the Cold War was in full...   \n",
       "59            825  During the 18th and 19th centuries, clay forma...   \n",
       "77            823  It is not often spoken about, but it’s an unse...   \n",
       "78            823  In these modern times, death is portrayed as u...   \n",
       "88            823  Created to remember the hundreds of Swiss Guar...   \n",
       "91            820  This small forest in the Bronx could be the mo...   \n",
       "92            821  This “Odditorium” features a collection of ove...   \n",
       "\n",
       "                                       placeShortDesc  \\\n",
       "3   The site of a tragic massacre that spawned a m...   \n",
       "6   Performers, intricate sets, and a real speakea...   \n",
       "13  This colorful theme park dedicated the officia...   \n",
       "39  A real flying saucer, contracted by the U.S. A...   \n",
       "59  This dig site outside D.C. is known for its ex...   \n",
       "77  \"Not too many people can say they've had a nuc...   \n",
       "78  A wild west cemetery in Tombstone, Arizona, pr...   \n",
       "88  This memorial commemorating fallen Swiss Guard...   \n",
       "91  This plot of old-growth forest is the largest ...   \n",
       "92  An ever-growing collection of rare and strange...   \n",
       "\n",
       "                                          placeNearby  \\\n",
       "3   The Long Island Puppet Theater,Pilgrim Psychia...   \n",
       "6   The Paris Market,Riverside Plant Hotel,The Mar...   \n",
       "13  Maine Central Model Railroad,Maine Coast Sardi...   \n",
       "39  National Museum of the U.S. Air Force,SAM 2600...   \n",
       "59  Smokey Bear Archive,On the Brink,Pinball Parlo...   \n",
       "77  The Last Yogi Bear Honey Fried Chicken Restaur...   \n",
       "78  Jewish Pioneers Memorial,Rose Tree Museum,St. ...   \n",
       "88  Barabas Hotel Luzern,Dance of Death Bridge,Ham...   \n",
       "91  Fordham Cemetery,Bronx Zoo 'Fountain of Youth'...   \n",
       "92  Josephine Tussaud Wax Museum ,The Arlington Ho...   \n",
       "\n",
       "                                          placeAdress  placeAlt  placeLong  \\\n",
       "3   112 Ocean Avenue Amityville, New York, 11701 U...   40.6665   -73.4143   \n",
       "6   209 W. St. Julian Street Savannah, Georgia Uni...   32.0806   -81.0946   \n",
       "13  1067 US HWY 1 Columbia Falls, Maine United States   44.6487   -67.7069   \n",
       "39  1100 Spaatz Street Wright-Patterson AFB Dayton...   39.7822   -84.1077   \n",
       "59  13100 Mid Atlantic Blvd Laurel, Maryland Unite...   39.0708   -76.8686   \n",
       "77  Crater Rd. Mars Bluff Florence, South Carolina...   34.2011   -79.6564   \n",
       "78  Boothill Graveyard 408 Arizona Hwy 80 Tombston...   31.7199  -110.0702   \n",
       "88         Denkmalstrasse 4 Lucerne, 6006 Switzerland   47.0585     8.3109   \n",
       "91   2900 Southern Blvd Bronx, New York United States   40.8644   -73.8757   \n",
       "92  817 Central Ave Hot Springs, Arkansas, 71901 U...   34.5087   -93.0539   \n",
       "\n",
       "                                         placeEditors         placePubDate  \\\n",
       "3   EricGrundhauser,MandrewPatinkin,lendog666,Mart...  2013-10-17 00:00:00   \n",
       "6   Edward Denny,Collector of Experiences,theparan...  2018-11-26 00:00:00   \n",
       "13                   Lauren J Young,basimonica11,hana  2016-08-16 00:00:00   \n",
       "39  canuck,Kiri the Unicorn,shaunk82,Ahuntley,mord...  2010-07-01 00:00:00   \n",
       "59     WhiskeyBristles,annakovach,ickaimp,kristingail  2017-06-05 00:00:00   \n",
       "77  rachel777,treytatum,Rachel,Martin,Mark Casey,z...  2013-03-19 00:00:00   \n",
       "78  Mark Casey,mordred350,CorpseLady84,Rachel,dlc3...  2012-04-03 00:00:00   \n",
       "88  ectoman3,Annetta Black,mikeslolady1,gzhtub,Mar...  2013-12-05 00:00:00   \n",
       "91      Luke J Spencer,vbl,Anna Minster,imrantabish16  2018-01-02 00:00:00   \n",
       "92  seh256,Erik,notoriousFIG,Collector of Experien...  2016-07-13 00:00:00   \n",
       "\n",
       "                                     placeRelatedList  \\\n",
       "3   The Long Island Puppet Theater,Fire Island Lig...   \n",
       "6   The Paris Market,Riverside Plant Hotel,The Mar...   \n",
       "13  Maine Central Model Railroad,Nellie Chapin Day...   \n",
       "39  SAM 26000,National Museum of the U.S. Air Forc...   \n",
       "59  Smokey Bear Archive,Pinball Parlor at MOM's Or...   \n",
       "77  Blenheim Mineral Springs,Woods Bay State Park,...   \n",
       "78  Jewish Pioneers Memorial,St. Paul’s Episcopal ...   \n",
       "88  Barabas Hotel Luzern,Dance of Death Bridge,Ham...   \n",
       "91  Holiday Train Show at New York Botanical Garde...   \n",
       "92  Josephine Tussaud Wax Museum ,The Arlington Ho...   \n",
       "\n",
       "                                    placeRelatedPlace  \\\n",
       "3   Conanicut Island Lighthouse,Lovell Health Hous...   \n",
       "6   Booze History Museum,Linos tou Charilaou (Omod...   \n",
       "13  Sadpol Strawberry,Monticello's Vegetable Garde...   \n",
       "39  Le Téléscaphe,Edison's Last Breath,Swing at th...   \n",
       "59  Capitalsaurus Court,Enciso Ichnites,Castilla-L...   \n",
       "77  Hiroshima's Hypocenter,Lucky Dragon and Atomic...   \n",
       "78  Boot Hill Cemetery,Grave of W. B. Yeats,John W...   \n",
       "88  Wellington Monument ,Napoleon's Angels,The Win...   \n",
       "91  Fragas do Eume,Trollskogen (The Troll Forest),...   \n",
       "92  The Insect Asylum ,Hand of Man Museum,Dreamfac...   \n",
       "\n",
       "                                             placeURL  \n",
       "3   https://www.atlasobscura.com/places/amityville...  \n",
       "6   https://www.atlasobscura.com/places/american-p...  \n",
       "13  https://www.atlasobscura.com/places/wild-blueb...  \n",
       "39        https://www.atlasobscura.com/places/avrocar  \n",
       "59  https://www.atlasobscura.com/places/laurel-din...  \n",
       "77  https://www.atlasobscura.com/places/mars-bluff...  \n",
       "78  https://www.atlasobscura.com/places/boothill-c...  \n",
       "88  https://www.atlasobscura.com/places/lion-of-lu...  \n",
       "91  https://www.atlasobscura.com/places/thain-fami...  \n",
       "92  https://www.atlasobscura.com/places/maxwell-bl...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first of all we execute the search engine as in 2.1 with the query given by the user\n",
    "dic1 = read_dic(\"dic1\")\n",
    "dic2 = read_dic(\"dic2\")\n",
    "s = query(query_user)\n",
    "res_query = data[data['placeName'].isin(list(s))]\n",
    "res_query.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the top rank visualization that you want to have? \n",
      "Insert \"1\" if you prefer that is by number of tourists. \n",
      "Insert \"2\" if you prefer that is by number of people that want to visit the site.1\n"
     ]
    }
   ],
   "source": [
    "n = int(input('What is the top rank visualization that you want to have? \\nInsert \"1\" if you prefer that is by number of tourists. \\nInsert \"2\" if you prefer that is by number of people that want to visit the site.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert k the number of places that you want to visualize:10\n",
      "Insert \"1\" if you want to see the k most popular places or insert \"2\" if you want to see the less famous places:1\n"
     ]
    }
   ],
   "source": [
    "k = int(input('Insert k the number of places that you want to visualize:')) \n",
    "s = int(input('Insert \"1\" if you want to see the k most popular places or insert \"2\" if you want to see the less famous places:'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0095c6ec66f02ae1bc8a134f6078f14ee669be44a5c4ac33d7f267434e255fcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
